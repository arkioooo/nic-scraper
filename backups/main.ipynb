{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0706284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait,Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "import undetected_chromedriver as uc\n",
    "from fake_useragent import UserAgent\n",
    "import re\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "from selenium.webdriver.remote.remote_connection import LOGGER\n",
    "import logging\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import os\n",
    "from rapidfuzz import process, fuzz\n",
    "from selenium.webdriver import ChromeOptions,Chrome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc44b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "LOGGER.setLevel(logging.ERROR)\n",
    "logging.getLogger(\"selenium\").setLevel(logging.CRITICAL)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"warnings.log\",\n",
    "    level=logging.WARNING,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "reverse_state_mapping = {\n",
    "    \"ANDAMAN AND NICOBAR ISLANDS\": \"35\",\n",
    "    \"ANDHRA PRADESH\": \"28\",\n",
    "    \"ARUNACHAL PRADESH\": \"12\",\n",
    "    \"ASSAM\": \"18\",\n",
    "    \"BIHAR\": \"10\",\n",
    "    \"CHANDIGARH\": \"4\",\n",
    "    \"CHHATTISGARH\": \"22\",\n",
    "    \"DELHI\": \"7\",\n",
    "    \"GOA\": \"30\",\n",
    "    \"GUJARAT\": \"24\",\n",
    "    \"HARYANA\": \"6\",\n",
    "    \"HIMACHAL PRADESH\": \"2\",\n",
    "    \"JAMMU AND KASHMIR\": \"1\",\n",
    "    \"JHARKHAND\": \"20\",\n",
    "    \"KARNATAKA\": \"29\",\n",
    "    \"KERALA\": \"32\",\n",
    "    \"LADAKH\": \"37\",\n",
    "    \"LAKSHADWEEP\": \"31\",\n",
    "    \"MADHYA PRADESH\": \"23\",\n",
    "    \"MAHARASHTRA\": \"27\",\n",
    "    \"MANIPUR\": \"14\",\n",
    "    \"MEGHALAYA\": \"17\",\n",
    "    \"MIZORAM\": \"15\",\n",
    "    \"NAGALAND\": \"13\",\n",
    "    \"ODISHA\": \"21\",\n",
    "    \"PUDUCHERRY\": \"34\",\n",
    "    \"PUNJAB\": \"3\",\n",
    "    \"RAJASTHAN\": \"8\",\n",
    "    \"SIKKIM\": \"11\",\n",
    "    \"TAMIL NADU\": \"33\",\n",
    "    \"TELANGANA\": \"36\",\n",
    "    \"DADRA AND NAGAR HAVELI AND DAMAN AND DIU\": \"38\",\n",
    "    \"TRIPURA\": \"16\",\n",
    "    \"UTTAR PRADESH\": \"9\",\n",
    "    \"UTTARAKHAND\": \"5\",\n",
    "    \"WEST BENGAL\": \"19\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def scrape_udyam(niccode,state):\n",
    "    href=f'https://udyamregistration.gov.in/SearchRegDetail.aspx?cod={niccode}&ty=2&si={reverse_state_mapping[state.upper()]}&di=0'  \n",
    "    return href\n",
    "\n",
    "def get_href(names, href):\n",
    "    all_rows = []\n",
    "    ua = UserAgent()\n",
    "    random_user_agent = ua.random\n",
    "\n",
    "    chrome_options = uc.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--disable-infobars\")\n",
    "    chrome_options.add_argument(\"--disable-extensions\")\n",
    "    chrome_options.add_argument(\"--incognito\")\n",
    "    chrome_options.add_argument(f\"user-agent={random_user_agent}\")\n",
    "    driver = uc.Chrome(options=chrome_options)\n",
    "\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "    try:\n",
    "        try:\n",
    "            driver.get(href)\n",
    "        except TimeoutException:\n",
    "            print(\"Page load timed out. Trying to stop loading manually.\")\n",
    "            driver.execute_script(\"window.stop();\")\n",
    "        try:\n",
    "            entries_dropdown = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"example1_length\"]/label/select')))\n",
    "            select = Select(entries_dropdown)\n",
    "            select.select_by_visible_text(\"All\")\n",
    "        except:\n",
    "            print(\"Dropdown not found or not interactable.\")\n",
    "\n",
    "        time.sleep(5)\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"example1\"]')))\n",
    "        try:\n",
    "            table = driver.find_element(By.XPATH, '//*[@id=\"example1\"]')\n",
    "            rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "            headers = [th.text.strip() for th in rows[0].find_elements(By.TAG_NAME, \"th\")]\n",
    "            headers.append(\"Business Email\")  # Add email column\n",
    "            data = []\n",
    "            for row in rows[1:]:\n",
    "                cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                row_data = [col.text.strip() for col in cols[:-1]]  # All except the last column\n",
    "                try:\n",
    "                    email_input = cols[-1].find_element(By.TAG_NAME, \"input\")\n",
    "                    email = email_input.get_attribute(\"value\")\n",
    "                except:\n",
    "                    email = \"\"\n",
    "                row_data.append(email)\n",
    "                data.append(dict(zip(headers, row_data)))\n",
    "            all_rows = data\n",
    "            print(f\"Rows captured: {len(all_rows)}\")\n",
    "        except Exception as e:\n",
    "            print('Table not found', {e})\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while processing the table.\", e)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4ce2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping NICs:   0%|          | 1/1127 [00:01<31:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved backup with 0 results\n",
      "Saved backup with 0 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping NICs:   0%|          | 3/1127 [00:02<14:54,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved backup with 0 results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping NICs:   0%|          | 4/1127 [00:04<18:31,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved backup with 0 results\n",
      "Error occurred while processing the table. ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping NICs:   0%|          | 5/1127 [00:16<1:26:55,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved backup with 0 results\n",
      "Dropdown not found or not interactable.\n",
      "Dropdown not found or not interactable.\n",
      "Error occurred while processing the table. Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=137.0.7151.105)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x4f3b03+62899]\n",
      "\tGetHandleVerifier [0x0x4f3b44+62964]\n",
      "\t(No symbol) [0x0x3210f3]\n",
      "\t(No symbol) [0x0x2fff59]\n",
      "\t(No symbol) [0x0x394f7e]\n",
      "\t(No symbol) [0x0x3af6a9]\n",
      "\t(No symbol) [0x0x38e306]\n",
      "\t(No symbol) [0x0x35d670]\n",
      "\t(No symbol) [0x0x35e4e4]\n",
      "\tGetHandleVerifier [0x0x754793+2556483]\n",
      "\tGetHandleVerifier [0x0x74fd02+2537394]\n",
      "\tGetHandleVerifier [0x0x51a2fa+220586]\n",
      "\tGetHandleVerifier [0x0x50aae8+157080]\n",
      "\tGetHandleVerifier [0x0x51141d+184013]\n",
      "\tGetHandleVerifier [0x0x4fba68+95512]\n",
      "\tGetHandleVerifier [0x0x4fbc10+95936]\n",
      "\tGetHandleVerifier [0x0x4e6b5a+9738]\n",
      "\tBaseThreadInitThunk [0x0x77a15d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x77e7d09b+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x77e7d021+561]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping NICs:   0%|          | 5/1127 [00:22<1:24:01,  4.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while processing the table. Message: invalid session id: session deleted as the browser has closed the connection\n",
      "from disconnected: not connected to DevTools\n",
      "  (Session info: chrome=137.0.7151.105)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x4f3b03+62899]\n",
      "\tGetHandleVerifier [0x0x4f3b44+62964]\n",
      "\t(No symbol) [0x0x3210f3]\n",
      "\t(No symbol) [0x0x3108c0]\n",
      "\t(No symbol) [0x0x32e87f]\n",
      "\t(No symbol) [0x0x39514c]\n",
      "\t(No symbol) [0x0x3af6a9]\n",
      "\t(No symbol) [0x0x38e306]\n",
      "\t(No symbol) [0x0x35d670]\n",
      "\t(No symbol) [0x0x35e4e4]\n",
      "\tGetHandleVerifier [0x0x754793+2556483]\n",
      "\tGetHandleVerifier [0x0x74fd02+2537394]\n",
      "\tGetHandleVerifier [0x0x51a2fa+220586]\n",
      "\tGetHandleVerifier [0x0x50aae8+157080]\n",
      "\tGetHandleVerifier [0x0x51141d+184013]\n",
      "\tGetHandleVerifier [0x0x4fba68+95512]\n",
      "\tGetHandleVerifier [0x0x4fbc10+95936]\n",
      "\tGetHandleVerifier [0x0x4e6b5a+9738]\n",
      "\tBaseThreadInitThunk [0x0x77a15d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x77e7d09b+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x77e7d021+561]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup logging and data directories\n",
    "backup_dir = \"backups\"\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "backup_file = os.path.join(backup_dir, \"running_backup.csv\")  # Single backup file\n",
    "\n",
    "df = pd.read_excel('NIC_2008.xlsx')\n",
    "nic_codes = df.iloc[:, 0].astype(str)\n",
    "valid_nic_codes = nic_codes[nic_codes.str.len() == 5].tolist()\n",
    "\n",
    "test_state = \"KARNATAKA\"  # Change as needed\n",
    "\n",
    "all_results = []\n",
    "failed_nics = []\n",
    "\n",
    "def scrape_nic(nic):\n",
    "    href = scrape_udyam(nic, test_state)\n",
    "    try:\n",
    "        table_rows = get_href([], href)\n",
    "        if not table_rows:  # If no rows were found\n",
    "            failed_nics.append({\"NIC\": nic, \"State\": test_state, \"Reason\": \"No data found\"})\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        failed_nics.append({\"NIC\": nic, \"State\": test_state, \"Reason\": str(e)})\n",
    "        logging.error(f\"NIC: {nic}, State: {test_state}, Error: {e}\")\n",
    "        return []\n",
    "    \n",
    "    for row in table_rows:\n",
    "        row[\"NIC_Code\"] = nic\n",
    "        row[\"State\"] = test_state\n",
    "    return table_rows\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    futures = {executor.submit(scrape_nic, nic): nic for nic in valid_nic_codes}\n",
    "    for i, future in enumerate(tqdm(as_completed(futures), total=len(futures), desc=\"Scraping NICs\")):\n",
    "        nic = futures[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            all_results.extend(result)\n",
    "            \n",
    "            # Save/overwrite backup after each NIC code\n",
    "            pd.DataFrame(all_results).to_csv(backup_file, index=False)\n",
    "            print(f\"Saved backup with {len(all_results)} results\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed_nics.append({\"NIC\": nic, \"State\": test_state, \"Reason\": str(e)})\n",
    "            logging.error(f\"Failed to process NIC {nic}: {str(e)}\")\n",
    "\n",
    "# Save final results with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "pd.DataFrame(all_results).to_csv(f\"test_nic_state_companies_fulltable_{timestamp}.csv\", index=False)\n",
    "\n",
    "# Save failed NICs\n",
    "if failed_nics:\n",
    "    pd.DataFrame(failed_nics).to_csv(f\"failed_nics_{timestamp}.csv\", index=False)\n",
    "    print(f\"Number of failed NICs: {len(failed_nics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b43fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_excel('NIC_2008.xlsx')\n",
    "# nic_codes = df.iloc[:, 0].astype(str)\n",
    "# valid_nic_codes = nic_codes[nic_codes.str.len() == 5].tolist()\n",
    "\n",
    "# test_state = \"TAMIL NADU\"  # Change as needed\n",
    "\n",
    "# all_results = []\n",
    "# for nic in valid_nic_codes:\n",
    "#     href = scrape_udyam(nic, test_state)\n",
    "#     try:\n",
    "#         table_rows = get_href([], href)\n",
    "#     except Exception as e:\n",
    "#         table_rows = [{\"Error\": f\"{e}\"}]\n",
    "\n",
    "#     for row in table_rows:\n",
    "#         row[\"NIC_Code\"] = nic\n",
    "#         row[\"State\"] = test_state\n",
    "#         all_results.append(row)\n",
    "\n",
    "#         if len(all_results) % 1000 == 0:\n",
    "#             pd.DataFrame(all_results).to_csv(\"test_nic_state_companies_backup.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "# pd.DataFrame(all_results).to_csv(\"test_nic_state_companies_fulltable.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
